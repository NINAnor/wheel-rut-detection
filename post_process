#!/usr/bin/env python3
"""
/***************************************************************************
 Post-process results from wheel ruts detection from multispectral, high
 resolution, imagery

        begin                : 2021-09-30
        author               : Stefan Blumentrath
        email                : stefan.blumentrath@nina.no
        copyright            : (C) Norwegian Institute for Nature Research
 ***************************************************************************/
/***************************************************************************
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
 *   it under the terms of the GNU General Public License as published by  *
 *   the Free Software Foundation; either version 3 of the License, or     *
 *   (at your option) any later version.                                   *
 *                                                                         *
 ***************************************************************************/

inputs: directory (mapset or DL_output structure)
output: geopackage
output: raster map NiN 7TK

"""

import argparse
from io import StringIO
import os
from multiprocessing import Pool
from pathlib import Path
import subprocess
import sys
from tempfile import NamedTemporaryFile
from shutil import which

import numpy as np

if not "GRASSBIN" in os.environ:
    for grass_version in ["grass", "grass80", "grass82"]:
        if which(grass_version):
            os.environ["GRASSBIN"] = which(grass_version)
            break
        else:
            os.environ["GRASSBIN"] = ""

p = subprocess.Popen(
    [os.environ["GRASSBIN"], "--config", "version"], stdout=subprocess.PIPE
)
grass_check = p.communicate()[0]
if not grass_check or int(grass_check.decode()[0]) < 8:
    sys.exit(
        "Could not find a GRASS GIS 8 (or later) installation.\n"
        "Please install it or provide the path in the GRASSBIN environment variable."
    )

os.environ["GRASS_ADDON_BASE"] = "~/.grass8/addons"

# ToDo
# Check NDVI computation and classification
# Add summary
# Better defaults for aerial images
# Use system GRASS

# Example
# ./post_process -nprocs 4 -verbose -proc_win 410600 7700655 411055 7700300
# -output /tmp -workdir /tmp -prefix balsfjord
# -dtm /data/P-Prosjekter/15215600_autmatisert_kartlegging_av_barmarksskader/ODM_results/P4P_Skutviksvatnet_Day2/P4P_Skutviksvatnet_Day2_dsm.tif
# -input /data/P-Prosjekter/15215600_autmatisert_kartlegging_av_barmarksskader/NIBIO/20211213_tmp_results_all_drone/balsfjord_drone/
# -roads=$HOME/drone/Balsfjord_roads.shp -streams=$HOME/drone/Balsfjord_streams.shp
# -resolution 0.15 -overwrite

try:
    from grass_session import Session
except Exception:
    sys.exit(
        'The "grass_session" python library cannot be imported, make sure it is installed with"python3 -m pip install grass_session"'
    )


def rmap_exists(mapname):
    """Check if a raster map exists"""
    return RasterRow(mapname).exist()


def vmap_exists(mapname):
    """Check if a raster map exists"""
    return VectorTopo(mapname).exist()


def assign_nodata(file):
    """Assign val as NoData"""
    subprocess.run(["gdal_edit.py", "-unsetnodata", str(file)])


def cleanup(maps, mtype):
    """Remove no longer needed temporary maps"""
    Module(
        "g.remove",
        quiet=True,
        type=mtype,
        name=",".join(maps),
        flags=["f", "b"],
        stderr_=subprocess.DEVNULL,
    )


def import_predictions(args):
    """Import model prediction"""
    if rmap_exists(f'{args["prefix"]}_mosaik') and not args["overwrite"]:
        gscript.verbose(f'{args["prefix"]}_mosaik exists, skipping...')
        return f'{args["prefix"]}_mosaik'
    assign_nodata(args["input"])
    map_import = Module(
        "r.external",
        flags=["m"],  # "om": empty files fail to link with m or f flag
        overwrite=True,
        quiet=True,
        input=str(args["input"]),
        output=f'{args["prefix"]}_mosaik',
        stderr_=subprocess.PIPE,
    )
    if "error" in map_import.outputs["stderr"].value.lower():
        gscript.warning(f'File {args["input"].stem} is invalid or empty')
    else:
        gscript.verbose(f'{args["input"]} imported')
        return f'{args["prefix"]}_mosaik'


def setup_tiling(args):
    """Define tiles to process"""
    tiles = f'{args["prefix"]}_tiles'
    reg = gscript.parse_command(
        "g.region",
        flags="g{}".format("a" if args["resolution"] else ""),
        n=args["proc_win"][1] if args["proc_win"] else None,
        s=args["proc_win"][3] if args["proc_win"] else None,
        w=args["proc_win"][0] if args["proc_win"] else None,
        e=args["proc_win"][2] if args["proc_win"] else None,
        raster=f'{args["prefix"]}_mosaik' if not args["proc_win"] else None,
        res=args["resolution"],
        align=f'{args["prefix"]}_mosaik' if not args["resolution"] else None,
    )

    tiled_processing = True

    if not args["overwrite"] and vmap_exists(tiles):
        return reg, tiled_processing

    if args["tiling"]:
        Module(
            "v.mkgrid",
            quiet=True,
            map=tiles,
            grid=args["tiling"],
            overwrite=args["overwrite"],
        )
    elif args["nprocs"] > 1:
        if int(reg["rows"]) > int(reg["cols"]):
            height = int(int(reg["rows"]) / args["nprocs"])
            height += 1 if int(reg["rows"]) % args["nprocs"] > 0 else 0
            width = int(reg["cols"])
            rows = args["nprocs"]
            cols = 1
        else:
            width = int(int(reg["cols"]) / args["nprocs"])
            width += 1 if int(reg["cols"]) % args["nprocs"] > 0 else 0
            height = int(reg["rows"])
            rows = 1
            cols = args["nprocs"]
        Module(
            "v.mkgrid",
            quiet=True,
            map=tiles,
            grid=[rows, cols],
            overwrite=args["overwrite"],
        )
    else:
        tiled_processing = False

    return reg, tiled_processing


def get_tile_bboxes(args, tiled_processing):
    """Compute bounding boxes for tiles"""
    if not tiled_processing:
        return None

    bboxes = []
    tileset = f'{args["prefix"]}_tiles'
    tile_map = VectorTopo(tileset)
    tile_map.open(mode="r")
    for tile in tile_map.viter("areas"):
        bboxes.append(
            (
                int(tile.attrs.cat),
                {
                    "n": tile.bbox().north,
                    "s": tile.bbox().south,
                    "e": tile.bbox().east,
                    "w": tile.bbox().west,
                },
            )
        )
    return bboxes


def bbox2regenv(bbox, region, overlap=0, align_rmap=None, res=None):
    """Create region environment from bounding box"""
    # Setup region environment
    g_env = os.environ.copy()
    ns_overlap = overlap * (res or float(region["nsres"]))
    ew_overlap = overlap * (res or float(region["ewres"]))
    g_env["GRASS_REGION"] = gscript.region_env(
        n=str(min(bbox[1]["n"] + ns_overlap, float(region["n"]))),
        s=str(max(bbox[1]["s"] - ns_overlap, float(region["s"]))),
        e=str(min(bbox[1]["e"] + ew_overlap, float(region["e"]))),
        w=str(max(bbox[1]["w"] - ew_overlap, float(region["w"]))),
        nsres=res or float(region["nsres"]),
        ewres=res or float(region["ewres"]),
        align=align_rmap,
        flags="a" if align_rmap is None else None,
    )
    return g_env


def resample(args, mapname, bbox, region):
    """Resample raster map to desired resolution"""
    tile_prefix = "{}_tile_{}".format(args["prefix"], str(bbox[0]).zfill(3))

    genv_tile = bbox2regenv(
        # bbox, region, overlap=0, align_rmap=f'{args["prefix"]}_mosaik', res=None
        bbox,
        region,
        overlap=0,
        align_rmap=None,
        res=args["resolution"],
    )
    # Resample to target resolution
    mm = Module(
        "r.resamp.stats",
        run_=False,
        env_=genv_tile,
        overwrite=args["overwrite"],
        quiet=True,
        input=f'{args["prefix"]}_{mapname}',
        output=f"{tile_prefix}_{mapname}_res",
        method="mode",
    )
    return mm, [f"{mapname}_res"]


def extract_lines_and_areas(args, bbox, region):
    """Classify and filter objects by width and size"""
    trac_half_max_width_int = int((args["maximum_width"] ** 2 / 2.0))
    trac_half_min_width_int = int((args["minimum_width"] ** 2 / 2.0))
    trac_half_min_width_int = max([trac_half_min_width_int, 1])

    tile_prefix = "{}_tile_{}".format(args["prefix"], str(bbox[0]).zfill(3))

    genv_tile = bbox2regenv(
        # bbox, region, overlap=0, align_rmap=f'{args["prefix"]}_mosaik', res=None
        bbox,
        region,
        overlap=0,
        align_rmap=None,
        res=args["resolution"],
    )
    genv_tile_overlap = bbox2regenv(
        bbox, region, overlap=25, align_rmap=None, res=args["resolution"]
    )

    nbh = 7

    mm = MultiModule(
        [
            # Smooth borders by buffering out and in
            Module(
                "r.neighbors",
                run_=False,
                env_=genv_tile_overlap,
                overwrite=True,
                quiet=True,
                input=f'{args["prefix"]}_mosaik_res_all',
                output=f"{tile_prefix}_extract_res_smooth",
                size=nbh,
                method="mode",
            ),
            Module(
                "r.reclass",
                run_=False,
                env_=genv_tile_overlap,
                overwrite=True,
                quiet=True,
                input=f"{tile_prefix}_extract_res_smooth",
                output=f"{tile_prefix}_extract_smoothed_pre_inv",
                rules="-",
                stdin_="0 = 1\n* = NULL",
            ),
            Module(
                "r.grow.distance",
                run_=False,
                env_=genv_tile_overlap,
                flags="m",
                overwrite=True,
                quiet=True,
                metric="squared",  # squared metric allows reclassification
                input=f"{tile_prefix}_extract_smoothed_pre_inv",
                distance=f"{tile_prefix}_inv_dist_buf",
            ),
            # Extract areas
            Module(
                "r.mapcalc",
                run_=False,
                env_=genv_tile,
                overwrite=True,
                quiet=True,
                expression=f"{tile_prefix}_extract_inv_dist_areas=if({tile_prefix}_inv_dist_buf>={(args['maximum_width']/2)**2},{args['prefix']}_mosaik_clumps,null())",
            ),
            # Extract lines
            Module(
                "r.mapcalc",
                run_=False,
                env_=genv_tile_overlap,
                overwrite=True,
                quiet=True,
                expression=f"{tile_prefix}_extract_inv_dist_lines=if({tile_prefix}_inv_dist_buf>={(args['minimum_width']/2)**2},{args['prefix']}_mosaik_clumps,null())",
            ),
            Module(
                "r.thin",
                run_=False,
                env_=genv_tile_overlap,
                overwrite=True,
                quiet=True,
                input=f"{tile_prefix}_extract_inv_dist_lines",
                output=f"{tile_prefix}_extract_lines",
            ),
            Module(
                "r.mapcalc",
                run_=False,
                env_=genv_tile,
                overwrite=True,
                quiet=True,
                expression=f"{tile_prefix}_lines={tile_prefix}_extract_lines",
            ),
            Module(
                "r.grow.distance",
                run_=False,
                env_=genv_tile_overlap,
                flags="m",
                quiet=True,
                overwrite=True,
                metric="squared",  # squared metric allows reclassification
                input=f"{tile_prefix}_extract_inv_dist_areas",
                value=f"{tile_prefix}_areas_extract_val",
                maximum_distance=(args["maximum_width"] / 2) ** 2,
            ),
            Module(
                "r.mapcalc",
                run_=False,
                env_=genv_tile,
                overwrite=True,
                quiet=True,
                expression=f"{tile_prefix}_areas_pre=int({tile_prefix}_areas_extract_val)",
            ),
            Module(
                "r.grow.distance",
                run_=False,
                quiet=True,
                env_=genv_tile_overlap,
                flags="m",
                overwrite=True,
                metric="squared",  # squared metric allows reclassification
                input=f"{tile_prefix}_extract_inv_dist_lines",
                value=f"{tile_prefix}_mosaik_smoothed",
                maximum_distance=(args["minimum_width"] / 2) ** 2,
            ),
            Module(
                "g.remove",
                run_=False,
                quiet=True,
                flags=["f", "b"],
                type="raster",
                pattern=f"{tile_prefix}_extract*",
                stderr_=subprocess.DEVNULL,
            ),
        ]
    )
    return mm, ["areas_pre", "lines", "mosaik_smoothed", "inv_dist_buf"]


def clean_vector_lines(lines, min_length, minimum_gap):
    """Clean dangling segments from vector lines after thinning"""
    Module(
        "v.net.components",
        overwrite=True,
        quiet=True,
        input=lines,
        output=f"{lines}_clean_net",
        method="strong",
    )
    Module(
        "v.reclass",
        overwrite=True,
        quiet=True,
        input=f"{lines}_clean_net",
        type="line",
        output=f"{lines}_clean_net_rc",
        column="comp",
    )
    Module(
        "v.distance",
        overwrite=True,
        quiet=True,
        flags="a",
        from_=f"{lines}_clean_net_rc",
        from_type="line",
        to=f"{lines}_clean_net_rc",
        to_type="line",
        # to_column="cat",
        upload=["cat", "dist"],
        output=f"{lines}_clean_connections",
        table=f"{lines}_clean_connections",
        column=["to_cat", "dist"],
        dmin=0.1,
        dmax=minimum_gap,
    )
    Module(
        "v.extract",
        overwrite=True,
        quiet=True,
        input=f"{lines}_clean_connections",
        type="line",
        where=f"cat in (SELECT DISTINCT cat FROM (SELECT DISTINCT cat, from_cat, to_cat FROM {lines}_clean_connections WHERE from_cat != to_cat GROUP BY CASE WHEN from_cat > to_cat THEN to_cat || '_' || from_cat ELSE from_cat || '_' || to_cat END ORDER BY dist) ORDER BY cat)",
        output=f"{lines}_clean_connections_rel",
    )
    Module(
        "v.patch",
        overwrite=True,
        quiet=True,
        # flags=["b"],
        input=[lines, f"{lines}_clean_connections_rel"],
        output=f"{lines}_clean_patch",
    )
    Module(
        "v.edit",
        flags="r",
        quiet=True,
        map=f"{lines}_clean_patch",
        type="line",
        tool="snap",
        threshold=[0, 0.05, 0],
        ids=-9999,
        snap="vertex",
    )
    Module(
        "v.edit",
        quiet=True,
        flags="r",
        map=f"{lines}_clean_patch",
        type="line",
        tool="break",
        threshold=[0, 0.05, 0],
        ids=-9999,
        snap="vertex",
    )
    Module(
        "v.clean",
        overwrite=True,
        quiet=True,
        input=f"{lines}_clean_patch",
        output=f"{lines}_clean_break",
        tool=["snap", "break", "rmline", "rmdupl"],
        threshold=[0.01, 0.00, 0.00, 0.00],
        type="line",
    )
    Module(
        "v.category",
        overwrite=True,
        quiet=True,
        flags="t",
        input=f"{lines}_clean_break",
        output=f"{lines}_clean_cat",
        layer=2,
        type="line",
        option="add",
    )
    Module(
        "v.extract",
        overwrite=True,
        quiet=True,
        flags="t",
        input=f"{lines}_clean_cat",
        layer=2,
        type="line",
        output=f"{lines}_clean_extract",
    )
    Module(
        "v.build.polylines",
        overwrite=True,
        quiet=True,
        input=f"{lines}_clean_cat",
        output=f"{lines}_clean_poly",
        cats="first",
        type="line",
    )
    Module(
        "v.net",
        overwrite=True,
        quiet=True,
        flags="c",
        input=f"{lines}_clean_poly",
        output=f"{lines}_clean_poly_net",
        operation="nodes",
        arc_type="line",
    )
    net = np.genfromtxt(
        Module(
            "v.net",
            flags="c",
            quiet=True,
            input=f"{lines}_clean_poly_net",
            operation="report",
            stdout_=subprocess.PIPE,
        )
        .outputs["stdout"]
        .value.strip()
        .split("\n"),
        delimiter=" ",
        dtype=np.int,
    )
    # Add two rows with 1
    net = np.c_[net, np.ones(np.shape(net[:, 0]))]
    net = np.c_[net, np.ones(np.shape(net[:, 0]))]
    # Identify core and start/end nodes
    node_count = np.unique(np.r_[net[:, 1], net[:, 2]], return_counts=True)
    start_end_nodes = node_count[0][np.where(node_count[1] == 1)]
    f_idx = np.intersect1d(net[:, 1], start_end_nodes, return_indices=True)
    t_idx = np.intersect1d(net[:, 2], start_end_nodes, return_indices=True)
    net_idx = list(set(sorted(sorted(f_idx[1]) + sorted(t_idx[1]))))
    # Assign 0 to lines that connect other lines (no start or end)
    net[:, 3] = 0
    net[:, 3][net_idx] = 1

    length = np.genfromtxt(
        Module(
            "v.to.db",
            quiet=True,
            flags="p",
            map=f"{lines}_clean_poly_net",
            type="line",
            option="length",
            units="meters",
            stdout_=subprocess.PIPE,
        )
        .outputs["stdout"]
        .value.strip()
        .split("\n"),
        delimiter="|",
        skip_header=1,
        dtype=None,
    )
    # Assign 0 to lines longer than x m
    l_idx = np.intersect1d(
        net[:, 0],
        length["f0"][np.where(length["f1"] > min_length)],
        return_indices=True,
    )
    net[:, 4][l_idx[1]] = 0
    cats = net[:, 0][np.where(((net[:, 3] < 1) | (net[:, 4] < 1)))]
    Module(
        "v.extract",
        overwrite=True,
        quiet=True,
        input=f"{lines}_clean_poly_net",
        output=f"{lines}_core",
        cats=",".join(cats.astype("i4").astype(np.str)),
        type="line",
        layer=1,
    )
    Module(
        "g.remove",
        quiet=True,
        type="vector",
        pattern=f"{lines}_clea*",
        flags="f",
        stderr_=subprocess.DEVNULL,
    )


def run_modules(modules, result_suffixes, args):
    """Run GRASS module objects in a parallel module queue and build vrt from results"""
    mod_queue = ParallelModuleQueue(nprocs=int(args["nprocs"]))
    for mod in modules:
        # Setup region environment
        mod_queue.put(mod)
    mod_queue.wait()

    # Patch tiles
    for result_suffix in result_suffixes:
        Module(
            "r.buildvrt",
            input=gscript.read_command(
                "g.list",
                flags="e",
                quiet=True,
                type="raster",
                pattern=f".*[0-9]_{result_suffix}$",
                mapset=".",
            )
            .rstrip()
            .split("\n"),
            output=f'{args["prefix"]}_{result_suffix}_all',
            overwrite=True,
            quiet=True,
        )
    return 0


def export_7TK(args, rmap):
    """Comput and export 7TK maps"""
    gscript.verbose(_("Computing and exporting 7TK maps"))
    color_rules = [
        "0 255:255:255",
        "20 230:180:180",
        "40 230:140:140",
        "60 235:95:9",
        "80 240:50:50",
        "100 240:10:10",
        "default grey",
        "end",
    ]
    map_info = gscript.parse_command("r.info", quiet=True, map=rmap, flags="g")

    mod_queue = ParallelModuleQueue(nprocs=2)
    for res in [10, 100]:
        g_env = os.environ.copy()
        g_env["GRASS_REGION"] = gscript.region_env(flags="a", raster=rmap, res=res)

        # Setup process
        resamp = MultiModule(
            [
                # Count wheel rut pixels
                Module(
                    "r.resamp.stats",
                    run_=False,
                    quiet=True,
                    env_=g_env,
                    overwrite=True,
                    input=rmap,
                    output=f'{args["prefix"]}_7TK_{res}_c',
                    method="count",
                ),
                # Rescale to percentage
                Module(
                    "r.mapcalc",
                    run_=False,
                    quiet=True,
                    env_=g_env,
                    overwrite=True,
                    expression=f'{args["prefix"]}_7TK_{res}=int(round(({args["prefix"]}_7TK_{res}_c / (({res} ^ 2) / (float({map_info["ewres"]}) * float({map_info["nsres"]}))))*100.0))',
                ),
                # Assign colors
                Module(
                    "r.colors",
                    run_=False,
                    quiet=True,
                    env_=g_env,
                    map=f'{args["prefix"]}_7TK_{res}',
                    rules="-",
                    stdin_="\n".join(color_rules),
                ),
                # Export to Cloud optimized GeoTiff
                Module(
                    "r.out.gdal",
                    run_=False,
                    env_=g_env,
                    overwrite=True,
                    quiet=True,
                    input=f'{args["prefix"]}_7TK_{res}',
                    output=str(
                        args["workdir"].joinpath(f'{args["prefix"]}_7TK_{res}.tif')
                    ),
                    type="Byte",
                    format="GTiff",
                    createopt="BIGTIFF=YES,COMPRESS=DEFLATE",
                ),
                # Export to Cloud optimized GeoTiff
                Module(
                    "g.remove",
                    run_=False,
                    env_=g_env,
                    quiet=True,
                    flags="f",
                    type="raster",
                    name=f'{args["prefix"]}_7TK_{res}_c',
                    stderr_=subprocess.DEVNULL,
                ),
            ]
        )
        mod_queue.put(resamp)

    # Run module queue
    mod_queue.wait()

    return 0


def export_7TK2(args, rmap):
    """Export raster map with NiN 7TK variable"""
    gscript.verbose(_("Computing and exporting 7TK maps"))
    # Define color rules
    color_rules = [
        "0 255:255:255",
        "20 230:180:180",
        "40 230:140:140",
        "60 235:95:9",
        "80 240:50:50",
        "100 240:10:10",
        "default grey",
        "end",
    ]

    resolutions = [10, 100]
    map_info = gscript.parse_command("r.info", map=rmap, flags="g")

    for idx, res in enumerate(resolutions):
        g_env = os.environ.copy()
        g_env["GRASS_REGION"] = gscript.region_env(flags="a", raster=rmap, res=res)

        # Count wheel rut pixels
        Module(
            "r.resamp.stats",
            env_=g_env,
            overwrite=True,
            quiet=True,
            input=f"{rmap}"
            if res == 10
            else f'{args["prefix"]}_7TK_{resolutions[idx - 1]}',
            output=f'{args["prefix"]}_7TK_{res}',
            method="maximum" if res == 10 else "count",
        )
        if res == 100:
            # Assign colors
            Module(
                "r.colors",
                quiet=True,
                env_=g_env,
                map=f'{args["prefix"]}_7TK_{res}',
                rules="-",
                stdin_="\n".join(color_rules),
            )
            # Export to Cloud optimized GeoTiff
            Module(
                "r.out.gdal",
                env_=g_env,
                overwrite=True,
                quiet=True,
                flags="f",
                input=f'{args["prefix"]}_7TK_{res}',
                output=str(args["workdir"].joinpath(f'{args["prefix"]}_7TK_{res}.tif')),
                type="Byte",
                format="GTiff",
                createopt="BIGTIFF=YES,COMPRESS=DEFLATE",
            )

    return 0


def check_userinput(args):
    """Check if input arguments are valid"""
    for in_path in ["workdir", "output", "roads", "streams", "dtm", "ndvi"]:
        if args[in_path]:
            if isinstance(args[in_path], str):
                args[in_path] = Path(args[in_path])
            if not args[in_path].exists:
                sys.exit(
                    "Error: Path <{str(args[in_path])}> provided in {in_path} option does not exist."
                )

            if in_path in ["workdir", "output"] and not os.access(
                args[in_path], os.W_OK
            ):
                sys.exit(
                    f"Error: No permission to write to directory <{str(args[in_path])}> provided in {in_path} option."
                )

            if in_path in ["roads", "streams", "dtm", "ndvi"] and not os.access(
                args[in_path], os.R_OK
            ):
                sys.exit(
                    f"Error: No permission to read file <{str(args[in_path])}> provided in {in_path} option."
                )

        elif in_path in ["workdir", "output"]:
            sys.exit(f"Error: Input for {in_path} is required.")

    if args["bands"]:
        if not "R" in args["bands"] or not "I" in args["bands"]:
            sys.exit(
                "Error: The band description needs to reference a red (R) and NIR band (I)."
            )

    if args["ndvi"] and not args["bands"]:
        sys.exit("Error: The ndvi option requires a band description.")

    if args["prefix"]:
        if not args["prefix"][0].isalpha():
            sys.exit("Error: prefix has to start with an alpha.")
    else:
        sys.exit("Error: Input for prefix is required.")

    if args["tiling"]:
        if isinstance(args["tiling"], str):
            try:
                args["tiling"] = tuple(int(t) for t in args["tiling"].split(","))
            except ValueError:
                sys.exit(
                    "Error: Only two numbers, separated by comma are valid input for tiling."
                )
        if not len(args["tiling"]) == 2:
            sys.exit(
                "Error: tiling input needs to be given as pair of numbers for rows and columns"
            )

    if args["proc_win"]:
        if isinstance(args["proc_win"], str):
            try:
                args["proc_win"] = tuple(
                    float(c) for c in args["proc_win"].strip().split(" ")
                )
            except ValueError:
                sys.exit(
                    "Error: Only four numbers, separated by space are valid input for tiling."
                )
        if not len(args["proc_win"]) == 4:
            sys.exit(
                "Error: Prcess window coordinates needsto be given as four numbers for West North East Souths"
            )

    if isinstance(args["input"], str):
        args["input"] = Path(args["input"])
        if not args["input"].exists:
            sys.exit(
                "Error: Input directory <{}> does not exist.".format(str(args["input"]))
            )

    if not os.access(args["input"], os.R_OK):
        sys.exit(
            "Error: Input directory <{}> is not readable.".format(str(args["infile"]))
        )

    for option in ["maximum_width", "minimum_length", "minimum_width", "resolution"]:
        if option == "resolution":
            if not args[option]:
                continue
        if not isinstance(args[option], float):
            try:
                args[option] = float(args[option])
            except:
                sys.exit(f"Error: Only float input is vaid for option {option}")

    for option in ["nprocs"]:
        if not isinstance(args[option], int):
            try:
                args[option] = int(args[option])
            except:
                sys.exit(f"Error: Only integer input is vaid for option {option}")

    for option in ["verbose", "overwrite"]:
        if not isinstance(args[option], bool):
            sys.exit(f"Error: Only boolean input is vaid for option {option}")

    return args


def classify_object_size(args):
    """Create reclass map with object size"""
    Module(
        "r.reclass",
        overwrite=True,
        quiet=True,
        input=f"{args['prefix']}_mosaik_res_all",
        output=f"{args['prefix']}_mosaik_rc",
        rules="-",
        stdin_="1 = 1\n* = NULL",
    )
    Module(
        "r.clump",
        overwrite=True,
        quiet=True,
        flags=["d"],
        input=f"{args['prefix']}_mosaik_rc",
        output=f"{args['prefix']}_mosaik_clumps",
    )
    rc_file_name = args["workdir"].joinpath("size_rc.txt")
    with open(rc_file_name, "w") as rc_file:
        rc_file.write(
            Module(
                "r.stats",
                quiet=True,
                flags=["a", "n"],
                input=f"{args['prefix']}_mosaik_clumps",
                separator="=",
                stdout_=subprocess.PIPE,
            )
            .outputs["stdout"]
            .value
        )
        rc_file.write("*=NULL\n")
    stderr = (
        Module(
            "r.reclass",
            overwrite=args["overwrite"],
            quiet=True,
            input=f"{args['prefix']}_mosaik_clumps",
            output=f"{args['prefix']}_mosaik_size_rc",
            rules=str(rc_file_name),
            stderr_=subprocess.PIPE,
        )
        .outputs["stderr"]
        .value.strip()
    )
    if "error" in stderr.lower():
        gscript.fatal(_(stderr))
    return 0


def classify_object_length(args):
    """Create reclass map with object length"""
    np_arr = np.genfromtxt(
        Module(
            "v.to.db",
            quiet=True,
            flags=["p"],
            map=f"{args['prefix']}_lines_all",
            separator=",",
            option="length",
            units="meters",
            stdout_=subprocess.PIPE,
        )
        .outputs["stdout"]
        .value.strip()
        .split("\n"),
        delimiter=",",
        names=("cat", "length"),
        dtype=None,
    )
    np_arr["length"] = (np_arr["length"] * 100.0).astype(np.int)
    fo = StringIO()
    np.savetxt(fo, np_arr, delimiter="=", fmt="%i")
    fo.write("*=NULL\n")
    rc_file_name = args["workdir"].joinpath("length_rc.txt")
    with open(rc_file_name, "w") as rc_file:
        rc_file.write(fo.getvalue())

    stderr = (
        Module(
            "r.reclass",
            overwrite=args["overwrite"],
            quiet=True,
            input=f"{args['prefix']}_mosaik_clumps",
            output=f"{args['prefix']}_mosaik_length_rc",
            rules=str(rc_file_name),
            stderr_=subprocess.PIPE,
        )
        .outputs["stderr"]
        .value.strip()
    )
    if "error" in stderr.lower():
        gscript.fatal(_(stderr))
    return 0


# To dos:
# Handle areas
# generate spatial units (homogenous line sections)
# collect statistics
# connect lines within gaps (next step)


def identify_damage(args, bbox, region, damage_type):
    """Assess damage on soil or vegetation"""

    tile_prefix = "{}_tile_{}".format(args["prefix"], str(bbox[0]).zfill(3))

    # Define upper bounds of classes
    damage_classes = {
        "ndvi": {
            "depth": {
                "1": 100,
                "2": 350,
            },
            "n": {
                "1": 25,
                "2": 50,
            },
        },
        "dtm": {
            "depth": {
                "1": 0.01,
                "2": 0.1,
            },
            "n": {
                "1": 25,
                "2": 50,
            },
        },
    }

    # Define geomorphon settings
    geomorphon_settings = {
        "dtm": {
            "search": 17,
            "flat": 3,
            "dist": 1,
        },
        "ndvi": {
            "search": 17,
            "flat": 13,
            "skip": 6,
        },
    }

    genv_tile = bbox2regenv(
        # bbox, region, overlap=0, align_rmap=f'{args["prefix"]}_mosaik', res=None
        bbox,
        region,
        overlap=0,
        align_rmap=None,
        res=args["resolution"],
    )

    genv_tile_overlap = bbox2regenv(
        bbox, region, overlap=20, align_rmap=None, res=args["resolution"]
    )

    modules = []
    if not damage_type == "ndvi":
        modules.append(
            # Resample to target resolution
            Module(
                "r.resamp.stats",
                run_=False,
                env_=genv_tile_overlap,
                overwrite=True,
                quiet=True,
                input=args[damage_type],
                output=f"{tile_prefix}_{damage_type}_res",
                method="minimum",
            )
        )
    modules.extend(
        [
            # Smooth borders by buffering out and in
            Module(
                "r.geomorphon",
                run_=False,
                env_=genv_tile_overlap,
                overwrite=True,
                quiet=True,
                flags=["e"],
                elevation=f"{tile_prefix}_{damage_type}_res"
                if damage_type == "dtm"
                else f'{args["prefix"]}_ndvi_all',
                forms=f"{tile_prefix}_{damage_type}_forms",
                **geomorphon_settings[damage_type],
            ),
            Module(
                "r.mapcalc",
                run_=False,
                env_=genv_tile_overlap,
                overwrite=True,
                quiet=True,
                expression="{tile_prefix}_{damage_type}_formbounds=if({forms}!=9&&{forms}!=10, if({forms}[0,1]>=9||{forms}[1,0]>=9||{forms}[1,1]>=9|| {forms}[-1,-1]>=9||{forms}[-1,1]>=9||{forms}[1,-1]>=9|| {forms}[0,-1]>=9||{forms}[-1,0]>=9, {damage_map},null()),null())".format(
                    damage_map=args[damage_type],
                    forms=f"{tile_prefix}_{damage_type}_forms",
                    tile_prefix=tile_prefix,
                    damage_type=damage_type,
                ),
            ),
            Module(
                "r.mapcalc",
                run_=False,
                env_=genv_tile_overlap,
                overwrite=True,
                quiet=True,
                expression="{tile_prefix}_{damage_type}_coreforms=if({forms}>=6&&{forms}<=8,if({forms}[0,1]>=9||{forms}[1,0]>=9||{forms}[1,1]>=9||{forms}[-1,-1]>=9||{forms}[-1,1]>=9||{forms}[1,-1]>=9||{forms}[0,-1]>=9||{forms}[-1,0]>=9,{damage_map},null()),if({forms}>=9,{damage_map},null()))".format(
                    forms=f"{tile_prefix}_{damage_type}_forms",
                    tile_prefix=tile_prefix,
                    damage_map=args[damage_type],
                    damage_type=damage_type,
                ),
            ),
            Module(
                "r.mapcalc",
                run_=False,
                env_=genv_tile_overlap,
                overwrite=True,
                quiet=True,
                expression="{tile_prefix}_{damage_type}_formbounds=if(isnull({coreforms}), if((!isnull({coreforms}[0,1]) || !isnull({coreforms}[1,0]) || !isnull({coreforms}[1,1]) || !isnull({coreforms}[-1,-1]) || !isnull({coreforms}[-1,1]) || !isnull({coreforms}[1,-1]) || !isnull({coreforms}[0,-1]) || !isnull({coreforms}[-1,0])), {damage_map}, null()),null())".format(
                    coreforms=f"{tile_prefix}_{damage_type}_coreforms",
                    tile_prefix=tile_prefix,
                    damage_map=args[damage_type],
                    damage_type=damage_type,
                ),
            ),
            Module(
                "r.grow.distance",
                run_=False,
                env_=genv_tile_overlap,
                overwrite=True,
                quiet=True,
                input=f"{tile_prefix}_{damage_type}_formbounds",
                value=f"{tile_prefix}_{damage_type}_formbounds_height",
            ),
            Module(
                "r.mapcalc",
                run_=False,
                env_=genv_tile_overlap,
                overwrite=True,
                quiet=True,
                expression=f"{tile_prefix}_{damage_type}_destruction_depth=if({args['prefix']}_mosaik_smoothed_all,{tile_prefix}_{damage_type}_formbounds_height-{tile_prefix}_{damage_type}_coreforms,null())",
            ),
            Module(
                "r.neighbors",
                run_=False,
                env_=genv_tile_overlap,
                overwrite=True,
                quiet=True,
                flags="c",
                selection=f"{args['prefix']}_lines_all",
                input=f"{tile_prefix}_{damage_type}_destruction_depth",
                output=[
                    f"{tile_prefix}_{damage_type}_destruction_depth_min",
                    f"{tile_prefix}_{damage_type}_destruction_depth_n",
                    f"{tile_prefix}_{damage_type}_destruction_depth_q25",
                ],
                size=15,
                method=["maximum", "count", "quantile"],
                quantile=0.975,
            ),
            Module(
                "r.mapcalc",
                run_=False,
                env_=genv_tile,
                overwrite=True,
                quiet=True,
                stdin_=f"{tile_prefix}_line_{damage_type}_destruction_depth_min=if({args['prefix']}_lines_all,if(isnull({tile_prefix}_{damage_type}_destruction_depth_min), 0,if({tile_prefix}_{damage_type}_destruction_depth_min<{damage_classes[damage_type]['depth']['1']},1,if({tile_prefix}_{damage_type}_destruction_depth_min>{damage_classes[damage_type]['depth']['2']},3,2))),null())\n"
                + f"{tile_prefix}_line_{damage_type}_destruction_depth_n=if({args['prefix']}_lines_all,if({tile_prefix}_{damage_type}_destruction_depth_n==0, 0 ,if({tile_prefix}_{damage_type}_destruction_depth_n<{damage_classes[damage_type]['n']['1']},1,if({tile_prefix}_{damage_type}_destruction_depth_n>{damage_classes[damage_type]['n']['2']},3,2))),null())",
            ),
        ]
    )
    mm = MultiModule(modules)
    return mm, [
        # "line_destruction_depth_q25",
        f"line_{damage_type}_destruction_depth_min",
        f"line_{damage_type}_destruction_depth_n",
        f"{damage_type}_destruction_depth_min",
        f"{damage_type}_destruction_depth_n",
    ]


def export_vector_map(args, vmap):
    out_file = args["output"].joinpath(args["prefix"] + ".gpkg")
    flags = {True: ["s", "2", "m", "u"], False: ["s", "2", "m"]}
    Module(
        "v.out.ogr",
        quiet=True,
        overwrite=True,
        flags=flags[out_file.exists()],
        input=vmap,
        output=str(out_file),
        output_layer=vmap,
    )


def collect_line_statistics(args, bbox, region):

    tile_prefix = "{}_tile_{}".format(args["prefix"], str(bbox[0]).zfill(3))

    mc_expression = f'{tile_prefix}_line_statistics=int(if({args["prefix"]}_mosaik_size_rc > {args["minimum_size"]} || {args["prefix"]}_mosaik_length_rc > {args["minimum_length"]} * 100.0, if({tile_prefix}_lines, {tile_prefix}_lines*10000 '
    if args["ndvi"]:
        mc_expression += f'+if(isnull({args["prefix"]}_line_ndvi_destruction_depth_min_all), 0, {args["prefix"]}_line_ndvi_destruction_depth_min_all*1000)'
        mc_expression += f'+if(isnull({args["prefix"]}_line_ndvi_destruction_depth_n_all), 0, {args["prefix"]}_line_ndvi_destruction_depth_n_all*100)'

    if args["dtm"]:
        mc_expression += f'+if(isnull({args["prefix"]}_line_dtm_destruction_depth_min_all), 0, {args["prefix"]}_line_dtm_destruction_depth_min_all*10)'
        mc_expression += f'+if(isnull({args["prefix"]}_line_dtm_destruction_depth_n_all), 0, {args["prefix"]}_line_dtm_destruction_depth_n_all)'

    mc_expression += ", null()),null()))"

    genv_tile = bbox2regenv(
        # bbox, region, overlap=0, align_rmap=f'{args["prefix"]}_mosaik', res=None
        bbox,
        region,
        overlap=0,
        align_rmap=None,
        res=args["resolution"],
    )

    mm = MultiModule(
        [
            Module(
                "v.to.rast",
                run_=False,
                env_=genv_tile,
                overwrite=True,
                quiet=True,
                input=f"{args['prefix']}_areas_all",
                output=f"{tile_prefix}_areas",
                type="area",
                use="cat",
            ),
            Module(
                "v.to.rast",
                run_=False,
                env_=genv_tile,
                overwrite=True,
                quiet=True,
                input=f"{args['prefix']}_lines_all_core",
                output=f"{tile_prefix}_lines",
                type="line",
                use="cat",
            ),
            Module(
                "r.mapcalc",
                run_=False,
                env_=genv_tile,
                overwrite=True,
                quiet=True,
                expression=mc_expression,
            ),
        ]
    )
    return mm, ["line_statistics", "lines", "areas"]


def add_vector_attributes(args, geom_type):
    """Add available attributes to attribute table"""
    # Get width
    get_raster_attributes(
        args, geom_type, "inv_dist_buf", ["max", "third_quart"], "width"
    )
    if geom_type == "lines":
        Module(
            "v.to.db",
            overwrite=True,
            quiet=True,
            map=f'{args["prefix"]}_lines',
            type="line",
            option="length",
            columns="length_m",
            units="meters",
        )
        if args["dtm"] or args["ndvi"]:
            addcol_str = f'BEGIN TRANSACTION;\nALTER TABLE {args["prefix"]}_lines ADD COLUMN cluster integer;\n'
            update_str = f'UPDATE {args["prefix"]}_lines SET cluster=CAST(substr(CAST(cat AS text), 1, length(cat)-4) AS integer), '
            if args["dtm"]:
                addcol_str += f'ALTER TABLE {args["prefix"]}_lines ADD COLUMN surface_damage_depth integer;\n'
                addcol_str += f'ALTER TABLE {args["prefix"]}_lines ADD COLUMN surface_damage_extent integer;\n'

                update_str += "surface_damage_extent=CAST(substr(CAST(cat AS text), length(cat), 1) AS integer), "
                update_str += "surface_damage_depth=CAST(substr(CAST(cat AS text), length(cat)-1, 1) AS integer);"
            if args["ndvi"]:
                if update_str.endswith(";\n"):
                    update_str = update_str.replace(";\n", "\n")
                addcol_str += f'ALTER TABLE {args["prefix"]}_lines ADD COLUMN vegetation_damage_depth integer;\n'
                addcol_str += f'ALTER TABLE {args["prefix"]}_lines ADD COLUMN vegetation_damage_extent integer;\n'
                update_str += "vegetation_damage_extent = CAST(substr(CAST(cat AS text), length(cat)-2, 1) AS integer), "
                update_str += "vegetation_damage_depth = CAST(substr(CAST(cat AS text), length(cat)-3, 1)) AS integer);"
            update_str = update_str.rstrip(", ")
            update_str = update_str.rstrip(";\n")
            update_str += ";\nCOMMIT;\n"
        tmp_sql = args["workdir"].joinpath("attr.sql")
        tmp_sql.write_text(addcol_str + update_str)
        Module("db.execute", quiet=True, input=str(tmp_sql))

    else:
        Module(
            "v.to.db",
            overwrite=True,
            quiet=True,
            map=f'{args["prefix"]}_areas',
            type="centroid",
            option="area",
            columns="area_m2",
            units="meters",
        )
        if args["dtm"]:
            get_raster_attributes(
                args,
                geom_type,
                "dtm_destruction_depth_min",
                ["mean", "max"],
                "surface_damage_depth",
            )
            get_raster_attributes(
                args,
                geom_type,
                "dtm_destruction_depth_n",
                ["sum"],
                "surface_damage_extent",
            )
        if args["ndvi"]:
            get_raster_attributes(
                args,
                geom_type,
                "ndvi_destruction_depth_min",
                ["mean", "max"],
                "vegetation_damage_depth",
            )
            get_raster_attributes(
                args,
                geom_type,
                "ndvi_destruction_depth_n",
                ["sum"],
                "vegetation_damage_extent",
            )


def get_raster_attributes(args, geometry_type, rmap, methods, variable):
    """Extracts raster statistics of variables for objectsr"""
    stats = np.genfromtxt(
        Module(
            "r.univar",
            quiet=True,
            flags=["t", "e"],
            map=f'{args["prefix"]}_{rmap}_all',
            zones=f'{args["prefix"]}_{geometry_type}_all',
            stdout_=subprocess.PIPE,
        )
        .outputs["stdout"]
        .value.strip()
        .split("\n"),
        delimiter="|",
        names=True,
        dtype=None,
    )
    key_column = "cat"  # if geometry_type == "lines" else "value"
    raststats_sql_path = args["workdir"].joinpath(
        f"raststats_update_{geometry_type}.sql"
    )
    with open(raststats_sql_path, mode="w") as raststats_sql:
        raststats_sql.write("BEGIN TRANSACTION;\n")
        for method in methods:
            raststats_sql.write(
                f'ALTER TABLE {args["prefix"]}_{geometry_type} ADD COLUMN {variable}_{method} real;\n'
            )
        for srow in np.nditer(stats):
            srow = {
                m: "NULL" if np.isnan(srow[m]) else srow[m] for m in methods + ["zone"]
            }
            set_values = ", ".join(
                [f"{variable}_{method} = {srow[method]}" for method in methods]
            )
            raststats_sql.write(
                f'UPDATE {args["prefix"]}_{geometry_type} SET {set_values} WHERE {key_column} = {srow["zone"]};\n'
            )
        raststats_sql.write("COMMIT;\n")
    Module("db.execute", input=str(raststats_sql_path))
    raststats_sql_path.unlink()
    return 0


def create_vector_mask(args):
    """Create a mask for known roads and streams"""
    mask_features = []
    for mask_feature in ["roads", "streams"]:
        if args[mask_feature]:
            Module(
                "v.in.ogr",
                flags="o",
                overwrite=True,
                quiet=True,
                input=str(args[mask_feature]),
                output=mask_feature,
            )
            mask_features.append(mask_feature)

    if len(mask_features) == 2:
        Module(
            "v.patch",
            overwrite=True,
            quiet=True,
            input=mask_features,
            output="mask_features",
        )
    else:
        Module(
            "g.copy",
            overwrite=True,
            quiet=True,
            vector=f"{mask_features[0]},mask_features",
        )
    Module(
        "v.buffer",
        overwrite=True,
        quiet=True,
        input="mask_features",
        output=f'{args["prefix"]}_mask_features_buffer',
        distance=2,
    )
    Module(
        "v.overlay",
        overwrite=True,
        quiet=True,
        flags="t",
        ainput=f'{args["prefix"]}_tiles',
        binput=f'{args["prefix"]}_mask_features_buffer',
        output=f'{args["prefix"]}_inverse_mask',
        operator="not",
    )
    Module(
        "g.remove",
        quiet=True,
        flags="f",
        type="vector",
        name=["mask_features"] + mask_features,
        stderr_=subprocess.DEVNULL,
    )
    return 0


def create_raster_mask(args, bbox, region):
    """Create a mask for known roads and streams"""
    tile_prefix = "{}_tile_{}".format(args["prefix"], str(bbox[0]).zfill(3))
    genv_tile = bbox2regenv(
        # bbox, region, overlap=0, align_rmap=f'{args["prefix"]}_mosaik', res=None
        bbox,
        region,
        overlap=0,
        align_rmap=None,
        res=args["resolution"],
    )
    mm = Module(
        "v.to.rast",
        run_=False,
        env_=genv_tile,
        overwrite=True,
        quiet=True,
        input=f'{args["prefix"]}_inverse_mask',
        output=f"{tile_prefix}_inverse_mask",
        use="val",
    )
    return mm, ["inverse_mask"]


def compute_ndvi(args, bbox, region):
    """Compute NDVI from multispectral imagery"""

    tile_prefix = "{}_tile_{}".format(args["prefix"], str(bbox[0]).zfill(3))
    # NDVI = (NIR - Red) / (NIR + Red)
    ir = args["bands"].index("I") + 1
    r = args["bands"].index("R") + 1
    genv_tile = bbox2regenv(
        # bbox, region, overlap=0, align_rmap=f'{args["prefix"]}_mosaik', res=None
        bbox,
        region,
        overlap=0,
        align_rmap=None,
        res=args["resolution"],
    )
    genv_tile_org = bbox2regenv(
        # bbox, region, overlap=0, align_rmap=f'{args["prefix"]}_mosaik', res=None
        bbox,
        region,
        overlap=2,
        align_rmap=f"multispectral.ir",
    )

    # print(bbox)
    # print(genv_tile["GRASS_REGION"])
    # print(genv_tile_org["GRASS_REGION"])

    mm = MultiModule(
        [
            # Compute NDVI with original resolution
            Module(
                "r.mapcalc",
                quiet=True,
                run_=False,
                env_=genv_tile_org,
                overwrite=True,
                expression=f"{tile_prefix}_ndvi_org=int(round(((multispectral.ir-multispectral.r)/(multispectral.ir+multispectral.r))*1000))",
            ),
            # Resample to target resolution
            Module(
                "r.resamp.stats",
                run_=False,
                env_=genv_tile,
                overwrite=True,
                quiet=True,
                input=f"{tile_prefix}_ndvi_org",
                output=f"{tile_prefix}_ndvi",
                method="average",
            ),
                    ])
    return mm, ["ndvi"]


def filter_areas(args):
    """"""
    # Filter by size and length
    length_arr = np.genfromtxt(
        str(args["workdir"].joinpath("length_rc.txt")), delimiter="=", dtype=np.int
    )
    length_arr = length_arr[
        np.where(length_arr[:, 1] > (args["minimum_length"] * 100.0))
    ]
    size_arr = np.genfromtxt(
        str(args["workdir"].joinpath("size_rc.txt")), delimiter="=", dtype=np.int
    )
    size_arr = size_arr[np.where(size_arr[:, 1] > args["minimum_size"])]
    clumps = set(size_arr[:, 0].tolist() + length_arr[:, 0].tolist())
    rules = "\n".join([f"{c}=1\n" for c in clumps] + ["* = NULL"])
    Module(
        "r.reclass",
        overwrite=True,
        quiet=True,
        input=f'{args["prefix"]}_areas_pre_all',
        output=f"{args['prefix']}_areas_all",
        rules="-",
        stdin_=rules,
    )
    Module(
        "r.reclass",
        overwrite=True,
        quiet=True,
        input=f'{args["prefix"]}_mosaik_smoothed_all',
        output=f'{args["prefix"]}_mosaik_smoothed_rc',
        rules="-",
        stdin_=rules,
    )

    args["workdir"].joinpath("length_rc.txt").unlink()
    args["workdir"].joinpath("size_rc.txt").unlink()

    return 0


def main(args):
    """Do the main work"""
    args = check_userinput(args)

    # files = [f for f in args["input"].rglob("*.tif") if f.is_file()]

    # start a GRASS GIS session based on the input file
    # grassbin = "/tmp/grass/bin.x86_64-pc-linux-gnu/grass"

    with Session(
        gisdb=str(args["workdir"]),
        location=args["prefix"],
        create_opts=None
        if args["workdir"].joinpath(args["prefix"]).exists()
        else str(args["input"]),
        # loadlibs=True,
    ):
        os.environ["GRASS_OVERWRITE"] = "1" if args["overwrite"] else "0"
        os.environ["GRASS_VERBOSE"] = "3" if args["verbose"] else "0"

        # import GRASS GIS libraries
        global gscript, Mapset, Module, ParallelModuleQueue, MultiModule, RasterRow, VectorTopo
        import grass.script as gscript
        from grass.pygrass.gis import Mapset
        from grass.pygrass.modules.interface import (
            Module,
            ParallelModuleQueue,
            MultiModule,
        )
        from grass.pygrass.raster import RasterRow
        from grass.pygrass.vector import VectorTopo

        # Import predictions if needed
        if not rmap_exists(f'{args["prefix"]}_mosaik') or args["overwrite"]:
            gscript.verbose(_("Importing predictions"))
            # Import predictions
            import_predictions(args)

        # Setup computational region and tiling (bboxes)
        reg, tiled_processing = setup_tiling(args)
        bboxes = get_tile_bboxes(args, tiled_processing)

        # Create mask if masks are provided
        if any([mask in args for mask in ["roads", "streams"]]):
            if (
                not rmap_exists(f'{args["prefix"]}_inverse_mask_all')
                or args["overwrite"]
            ):
                create_vector_mask(args)
                mms = [create_raster_mask(args, bbox, reg) for bbox in bboxes]
                # Run modules in parallel
                run_modules([m[0] for m in mms], mms[0][1], args)
                Module(
                    "r.mask",
                    overwrite=True,
                    quiet=True,
                    raster=f'{args["prefix"]}_inverse_mask_all',
                )

        if args["resolution"]:
            # Resample to target resolution
            if not rmap_exists(f'{args["prefix"]}_mosaik_res_all') or args["overwrite"]:
                mms = [resample(args, "mosaik", bbox, reg) for bbox in bboxes]
                run_modules([m[0] for m in mms], mms[0][1], args)

        if not rmap_exists(f"{args['prefix']}_mosaik_size_rc") or args["overwrite"]:
            classify_object_size(args)

        if rmap_exists("MASK"):
            Module("r.mask", flags=["r"], quiet=True)

        # Extract lines and areas
        # Create module objects to run in parallel
        if (
            not all(
                [
                    rmap_exists(f"{args['prefix']}_{geom}_all")
                    for geom in ["lines", "areas"]
                ]
            )
            or args["overwrite"]
        ):
            gscript.verbose(_("Extracting lines and areas"))
            mms = [extract_lines_and_areas(args, bbox, reg) for bbox in bboxes]
            # Run modules in parallel
            run_modules([m[0] for m in mms], mms[0][1], args)

        if not vmap_exists(f"{args['prefix']}_lines_all") or args["overwrite"]:
            # Convert lines to vector
            Module(
                "r.to.vect",
                quiet=True,
                flags=["s", "v"],
                overwrite=True,
                input=f"{args['prefix']}_lines_all",
                output=f"{args['prefix']}_lines_all",
                type="line",
            )
        if not vmap_exists(f"{args['prefix']}_lines_all_core") or args["overwrite"]:
            # Convert lines to vector
            # Clean vector maps (close gaps and remove dangles)
            gscript.verbose(_("Cleaning vector data"))
            clean_vector_lines(
                f"{args['prefix']}_lines_all",
                args["minimum_length"],
                args["minimum_gap"],
            )

        if not rmap_exists(f"{args['prefix']}_mosaik_length_rc") or args["overwrite"]:
            classify_object_length(args)

        if not vmap_exists(f"{args['prefix']}_areas_all") or args["overwrite"]:
            # Fitler areas
            filter_areas(args)
            # Convert areas to vector
            Module(
                "r.to.vect",
                flags=["s"],
                quiet=True,
                overwrite=True,
                input=f"{args['prefix']}_areas_all",
                output=f"{args['prefix']}_areas_all",
                type="area",
            )
        # Compute soil damage depth from dtm if provided
        if args["dtm"]:
            if not rmap_exists("dtm") or args["overwrite"]:
                # Import DTM
                Module(
                    "r.external",
                    overwrite=True,
                    quiet=True,
                    flags="m",
                    input=str(args["dtm"]),
                    output="dtm",
                )
            args["dtm"] = "dtm"

            if (
                not rmap_exists(f"{args['prefix']}_line_dtm_destruction_depth_n_all")
                or args["overwrite"]
            ):
                gscript.verbose(_("Assessing impact on soil / terrain"))
                mms = [identify_damage(args, bbox, reg, "dtm") for bbox in bboxes]
                run_modules([m[0] for m in mms], mms[0][1], args)

        # Compute vegetation damage depth from NDVI if provided
        if args["ndvi"]:
            if not rmap_exists(f'{args["prefix"]}_ndvi_all') or args["overwrite"]:
                # Import DTM
                ir = args["bands"].index("I") + 1
                r = args["bands"].index("R") + 1
                Module(
                    "r.external",
                    overwrite=True,
                    quiet=True,
                    flags="r",
                    input=str(args["ndvi"]),
                    band=ir,
                    output="multispectral_org.ir",
                )
                Module(
                    "r.external",
                    overwrite=True,
                    quiet=True,
                    flags="r",
                    input=str(args["ndvi"]),
                    band=r,
                    output="multispectral_org.r",
                )
                mod_queue = ParallelModuleQueue(nprocs=2)
                mod_queue.put([
                Module(
                    "r.resamp.stats",
                    overwrite=True,
                    quiet=True,
                    input="multispectral_org.r",
                    output="multispectral.r",
                    method="average",
                ),
                Module(
                    "r.resamp.stats",
                    overwrite=True,
                    quiet=True,
                    input="multispectral_org.ir",
                    output="multispectral.ir",
                    method="average",
                ),
                        ])
                mod_queue.wait()

                gscript.verbose(_("Computing NDVI"))
                mms = [compute_ndvi(args, bbox, reg) for bbox in bboxes]
                run_modules([m[0] for m in mms], mms[0][1], args)
            args["ndvi"] = f'{args["prefix"]}_ndvi_all'

            # Adjust the following to NDVI
            if (
                not rmap_exists(f"{args['prefix']}_line_ndvi_destruction_depth_n_all")
                or args["overwrite"]
            ):
                gscript.verbose(_("Assessing impact on vegetation"))
                mms = [identify_damage(args, bbox, reg, "ndvi") for bbox in bboxes]
                run_modules([m[0] for m in mms], mms[0][1], args)

        if args["dtm"] or args["ndvi"]:
            if not vmap_exists(f"{args['prefix']}_lines") or args["overwrite"]:
                gscript.verbose(_("Collecting statistics"))
                mms = [collect_line_statistics(args, bbox, reg) for bbox in bboxes]
                run_modules([m[0] for m in mms], mms[0][1], args)
                Module(
                    "r.to.vect",
                    quiet=True,
                    flags=["s", "v"],
                    overwrite=True,
                    input=f"{args['prefix']}_line_statistics_all",
                    output=f"{args['prefix']}_lines",
                    type="line",
                )
        elif not vmap_exists(f"{args['prefix']}_lines") or args["overwrite"]:
            Module(
                "g.copy",
                quiet=True,
                vector=[f"{args['prefix']}_lines_all", f"{args['prefix']}_lines"],
            )

        if not vmap_exists(f"{args['prefix']}_areas") or args["overwrite"]:
            Module(
                "g.copy",
                quiet=True,
                vector=[f"{args['prefix']}_areas_all", f"{args['prefix']}_areas"],
            )

        Module(
            "db.execute",
            quiet=True,
            sql=f"CREATE INDEX IF NOT EXISTS {args['prefix']}_areas_value_idx ON {args['prefix']}_areas (value)",
        )

        gscript.verbose(_("Adding vector attributes"))
        add_vector_attributes(args, "lines")
        add_vector_attributes(args, "areas")

        # Export vector results
        gscript.verbose(_("Writing final results"))
        export_vector_map(args, f"{args['prefix']}_lines")
        export_vector_map(args, f"{args['prefix']}_areas")

        # Create and export 7TK maps
        export_7TK2(args, f'{args["prefix"]}_mosaik_smoothed_rc')
        print("Done")


if __name__ == "__main__":

    parser = argparse.ArgumentParser(
        description="Post-process results from identifcation of motor vehicle tracs "
        "in multispectral, high resolution imagery.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )

    parser.add_argument(
        "-verbose",
        dest="verbose",
        default=False,
        action="store_true",
        help="Give verbose progress information",
    )

    parser.add_argument(
        "-overwrite",
        dest="overwrite",
        default=False,
        action="store_true",
        help="Overwrite existing maps (default is skip recreation)",
    )

    parser.add_argument(
        "-input",
        dest="input",
        required=True,
        type=str,
        # nargs=1,
        help="Path to the input directory with results from previous steps",
    )

    parser.add_argument(
        "-output",
        type=str,
        dest="output",
        required=True,
        default="./",
        # nargs=1,
        help="Path to directory to store results.",
    )

    parser.add_argument(
        "-workdir",
        dest="workdir",
        required=True,
        type=str,
        # nargs=1,
        help="Path to working directory where analysis are run.\n"
        "Should have enough storage capacity.",
    )

    parser.add_argument(
        "-roads",
        dest="roads",
        required=False,
        type=str,
        # nargs=1,
        help="Path to an OGR readable file with data on roads.\n"
        "If the file contains several layers, the relevant layer has to be specified separated by space",
    )

    parser.add_argument(
        "-streams",
        dest="streams",
        required=False,
        type=str,
        # nargs=1,
        help="Path to an OGR readable file with data on streams.\n"
        "If the file contains several layers, the relevant layer has to be specified separated by space",
    )

    parser.add_argument(
        "-prefix",
        dest="prefix",
        required=True,
        type=str,
        # nargs=1,
        help="Prefix used for temporary maps and workdir",
    )

    parser.add_argument(
        "-tiling",
        dest="tiling",
        type=str,
        default=None,
        nargs="?",
        help="Number of rows and columns to use in tiled processing (e.g. '3,5')\n"
        "If not provided, tiling will be derived from the number of cores given in the nprocs option",
    )

    parser.add_argument(
        "-resolution",
        dest="resolution",
        type=float,
        default=0.15,
        nargs="?",
        help="The resolution to operate on.\n",
    )

    parser.add_argument(
        "-dtm",
        dest="dtm",
        type=str,
        default=None,
        nargs="?",
        help="Path to a DTM corresponding to the image to analyse, must be in a format readable by GDAL",
    )

    parser.add_argument(
        "-ndvi",
        dest="ndvi",
        type=str,
        default=None,
        nargs="?",
        help="Path to multispectral image for extraction of NDVI statistics for wheel ruts",
    )

    parser.add_argument(
        "-bands",
        dest="bands",
        type=str,
        default="BGREIA",
        nargs="?",
        help="Order of bands in input imagery for NDVI handling\n"
        "B:blue, G:green, R:red, E:red edge, I:NIR, A:alpha, other bands are currently ignored",
    )

    parser.add_argument(
        "-proc_win",
        dest="proc_win",
        type=float,
        default=None,
        nargs=4,
        help="Extent to process defined by upper left and lower right coordinates\n"
        "So, coordinates order should be W N E S, e.g.:\n"
        '-proc_win "-11000 785000 3000 772000"',
    )

    parser.add_argument(
        "-nprocs",
        dest="nprocs",
        default=1,
        type=int,
        nargs="?",
        help="Number of cores to use for parallel/tiled processing.",
    )

    parser.add_argument(
        "-minimum_length",
        dest="minimum_length",
        type=float,
        default=45.0,
        nargs="?",
        help="The minimum length of possible tracks in meter.",
    )

    parser.add_argument(
        "-minimum_width",
        dest="minimum_width",
        type=float,
        default=1.0,
        nargs="?",
        help="The minimum width of possible tracks in meter.",
    )

    parser.add_argument(
        "-maximum_width",
        dest="maximum_width",
        type=float,
        nargs="?",
        default=4.5,
        help="The maximum width of possible tracks in meter.\n"
        "Detected tracs wider than this threshold are considered sheet-like damages and mapped as areas",
    )

    parser.add_argument(
        "-minimum_size",
        dest="minimum_size",
        type=float,
        default=65.0,
        nargs="?",
        help="The minimum size of possible tracks objects to keep (in m2).\n"
        "Detected objects smaller than this size are discarded if not part of a network",
    )

    parser.add_argument(
        "-minimum_gap",
        dest="minimum_gap",
        type=float,
        default=3.0,
        nargs="?",
        help="The minimum size of possible tracks objects to keep (in m2).\n"
        "Detected objects closer to each other than this distance are treated as one",
    )

    main(vars(parser.parse_args()))
